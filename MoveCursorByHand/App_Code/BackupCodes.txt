CvInvoke.InRange(hsvCroppedFrame, new VectorOfDouble(new double[] { 119, 10, 52 }), new VectorOfDouble(new double[] { 160, 40, 130 }), hsvCroppedFrame);
CvInvoke.MedianBlur(hsvCroppedFrame, hsvCroppedFrame, 5);
Mat kernel = CvInvoke.GetStructuringElement(ElementShape.Ellipse, new Size(11, 11), new Point(5, 5));
CvInvoke.Dilate(hsvCroppedFrame, hsvCroppedFrame, kernel, new Point(-1, -1), 1, BorderType.Default, new MCvScalar());


SIFT sift = new SIFT();
VectorOfKeyPoint vKP1 = new VectorOfKeyPoint();
VectorOfKeyPoint vKP2 = new VectorOfKeyPoint();
VectorOfVectorOfPoint des1 = new VectorOfVectorOfPoint();
VectorOfVectorOfPoint des2 = new VectorOfVectorOfPoint();
sift.DetectAndCompute(filteredCroppedFrame, null, vKP1, des1, false);
sift.DetectAndCompute(filteredCroppedFrame, null, vKP2, des2, false);
FlannBasedMatcher flann = new FlannBasedMatcher();
flann.KnnMatch(des1, des2, 2, null);


Mat newFilteredCroppedFrame = new Mat();
                    CvInvoke.CvtColor(croppedFrame, newFilteredCroppedFrame, ColorConversion.Bgr2Gray);                   
                    if (firstFrameCaptured)
                    {
                        matcherThread = new Thread(() =>
                        {
                            Image<Gray, byte> grayScaleHandImage = new Image<Gray, byte>(Properties.Resources.grayscale_hand);
                            UMat modelImageUMat = grayScaleHandImage.Mat.GetUMat(AccessType.Read);                                                        
                            UMat observedImageUMat = newFilteredCroppedFrame.GetUMat(AccessType.Read);
                            KAZE sift = new KAZE();
                            VectorOfKeyPoint vKPModelImage = new VectorOfKeyPoint();
                            VectorOfKeyPoint vKPObservedImage = new VectorOfKeyPoint();
                            Mat desModelImage = new Mat();
                            Mat desObservedImage = new Mat();
                            sift.DetectAndCompute(modelImageUMat, null, vKPModelImage, desModelImage, false);
                            sift.DetectAndCompute(observedImageUMat, null, vKPObservedImage, desObservedImage, false);
                            KdTreeIndexParams index_params = new KdTreeIndexParams();
                            SearchParams search_params = new SearchParams();
                            DescriptorMatcher flann = new FlannBasedMatcher(index_params, search_params);
                            VectorOfVectorOfDMatch matches = new VectorOfVectorOfDMatch();
                            flann.Add(desModelImage);
                            flann.KnnMatch(desObservedImage, matches, 2, null);
                            Mat mask = new Mat(matches.Size, 1, DepthType.Cv8U, 1); ;
                            mask.SetTo(new MCvScalar(255));
                            Features2DToolbox.VoteForUniqueness(matches, 0.80, mask);
                            int nonZeroCount = CvInvoke.CountNonZero(mask);
                        });
                        matcherThread.Start();
                    }
                    if(matcherThread != null && !matcherThread.IsAlive)
                    {
                        matcherThread = new Thread(() =>
                        {
                            Image<Gray, byte> grayScaleHandImage = new Image<Gray, byte>(Properties.Resources.grayscale_hand);
                            UMat modelImageUMat = grayScaleHandImage.Mat.GetUMat(AccessType.Read);
                            UMat observedImageUMat = newFilteredCroppedFrame.GetUMat(AccessType.Read);
                            KAZE sift = new KAZE();
                            VectorOfKeyPoint vKPModelImage = new VectorOfKeyPoint();
                            VectorOfKeyPoint vKPObservedImage = new VectorOfKeyPoint();
                            Mat desModelImage = new Mat();
                            Mat desObservedImage = new Mat();
                            sift.DetectAndCompute(modelImageUMat, null, vKPModelImage, desModelImage, false);
                            sift.DetectAndCompute(observedImageUMat, null, vKPObservedImage, desObservedImage, false);
                            KdTreeIndexParams index_params = new KdTreeIndexParams();
                            SearchParams search_params = new SearchParams();
                            DescriptorMatcher flann = new FlannBasedMatcher(index_params, search_params);
                            VectorOfVectorOfDMatch matches = new VectorOfVectorOfDMatch();
                            flann.Add(desModelImage);
                            flann.KnnMatch(desObservedImage, matches, 2, null);
                            Mat mask = new Mat(matches.Size, 1, DepthType.Cv8U, 1); ;
                            mask.SetTo(new MCvScalar(255));
                            Features2DToolbox.VoteForUniqueness(matches, 0.80, mask);
                            int nonZeroCount = CvInvoke.CountNonZero(mask);
                            if (nonZeroCount >= 4)
                            {
                                nonZeroCount = Features2DToolbox.VoteForSizeAndOrientation(vKPModelImage, vKPObservedImage, matches, mask, 1.5, 20);
                                if(nonZeroCount >= 4)
                                {
                                    Mat homograpgy = Features2DToolbox.GetHomographyMatrixFromMatchedFeatures(vKPModelImage, vKPObservedImage, matches, mask, 2);
                                    Console.WriteLine("NonZero Count: " + nonZeroCount);
                                    Console.WriteLine("Matches Size: " + matches.Size);
                                    Mat result = new Mat();
                                    Features2DToolbox.DrawMatches(modelImageUMat, vKPModelImage, observedImageUMat, vKPObservedImage, matches, croppedFrame, new MCvScalar(0, 255, 0), new MCvScalar(0, 255, 0), mask);
                                    captureImageBox.Image = croppedFrame;
                                }
                            }
                        });
                        matcherThread.Start();
                    }


					private void OverlayHandImage2(ref Mat analyzeRectFrame, Point loc)
        {
            Image<Bgra, byte> handOverlayImage = new Image<Bgra, byte>(Properties.Resources.hand_overlay);
            Mat handOverlayMat = handOverlayImage.Mat;

            for (int y = Math.Max(0, loc.Y); y < analyzeRectFrame.Rows; y++)
            {
                int yy = y - loc.Y;

                if (yy >= handOverlayMat.Rows)
                    break;

                for (int x = 0; x < Math.Max(0, loc.X); x++)
                {
                    int xx = x - loc.X;

                    if (xx >= handOverlayMat.Cols)
                        break;

                    double opacity = ((double)handOverlayMat.Data.GetValue(yy * handOverlayMat.Step + xx * handOverlayMat.NumberOfChannels + 3) / 255);

                    for (int i = 0; opacity > 0 && i < analyzeRectFrame.NumberOfChannels; i++)
                    {
                        char foregroundPx = foreground.data[fY * foreground.step + fX * foreground.channels() + c];
                        char backgroundPx = background.data[y * background.step + x * background.channels() + c];
                        analyzeRectFrame.Data.[y * output.step + output.channels() * x + c] = backgroundPx * (1.- opacity) + foregroundPx * opacity;
                    }
                }
            }
        }


		private void OverlayHandImage2(ref Mat analyzeRectFrame)
        {
            Point loc = new Point(analyzeRectFrame.Width / 2, analyzeRectFrame.Height / 2);

            Image<Bgra, byte> handOverlayImage = new Image<Bgra, byte>(Properties.Resources.hand_overlay);
            Mat handOverlayMat = handOverlayImage.Mat;

            Image<Bgr, byte> analyzeRectImage = analyzeRectFrame.ToImage<Bgr, byte>();

            for (int y = Math.Max(0, loc.Y); y < analyzeRectFrame.Rows; y++)
            {
                int yy = y - loc.Y;

                if (yy >= handOverlayMat.Rows)
                    break;

                for (int x = Math.Max(0, loc.X); x < analyzeRectFrame.Cols; x++)
                {
                    int xx = x - loc.X;

                    if (xx >= handOverlayMat.Cols)
                        break;

                    int xCoordinate = ((yy * handOverlayMat.Step + xx * handOverlayMat.NumberOfChannels + 3) / (handOverlayMat.Width * handOverlayMat.NumberOfChannels)) % (handOverlayMat.Height);
                    int yCoordinate = ((yy * handOverlayMat.Step + xx * handOverlayMat.NumberOfChannels + 3) / handOverlayMat.NumberOfChannels) % (handOverlayMat.Width);
                    int zCoordinate = (yy * handOverlayMat.Step + xx * handOverlayMat.NumberOfChannels + 3) % handOverlayMat.NumberOfChannels;
                    byte obj = (byte)handOverlayImage.Data.GetValue(xCoordinate, yCoordinate, zCoordinate);
                    double opacity = (obj / 255);

                    for (int i = 0; opacity > 0 && i < analyzeRectFrame.NumberOfChannels; i++)
                    {
                        byte foregroundPx = (byte)handOverlayImage.Data.GetValue(((yy * handOverlayMat.Step + xx * handOverlayMat.NumberOfChannels + i) / (handOverlayMat.Width * handOverlayMat.NumberOfChannels)) % (handOverlayMat.Height), ((yy * handOverlayMat.Step + xx * handOverlayMat.NumberOfChannels + i) / handOverlayMat.NumberOfChannels) % (handOverlayMat.Width), (yy * handOverlayMat.Step + xx * handOverlayMat.NumberOfChannels + i) % handOverlayMat.NumberOfChannels);
                        byte backgroundPx = (byte)analyzeRectImage.Data.GetValue(((y * analyzeRectFrame.Step + x * analyzeRectFrame.NumberOfChannels + i) / (analyzeRectFrame.Width * analyzeRectFrame.NumberOfChannels)) % (analyzeRectFrame.Height), ((y * analyzeRectFrame.Step + x * analyzeRectFrame.NumberOfChannels + i) / analyzeRectFrame.NumberOfChannels) % (analyzeRectFrame.Width), (y * analyzeRectFrame.Step + x * analyzeRectFrame.NumberOfChannels + i) % analyzeRectFrame.NumberOfChannels);
                        analyzeRectImage.Data.SetValue((byte)(backgroundPx * (1 - opacity) + foregroundPx * opacity), ((y * analyzeRectFrame.Step + analyzeRectFrame.NumberOfChannels * x + i) / (analyzeRectFrame.Width * analyzeRectFrame.NumberOfChannels)) % (analyzeRectFrame.Height), ((y * analyzeRectFrame.Step + analyzeRectFrame.NumberOfChannels * x + i) / analyzeRectFrame.NumberOfChannels) % (analyzeRectFrame.Width), (y * analyzeRectFrame.Step + analyzeRectFrame.NumberOfChannels * x + i) % analyzeRectFrame.NumberOfChannels);
                    }
                }
            }
            analyzeRectFrame = analyzeRectImage.Mat.Clone();
        }